{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder \"D:\\OneDrive\\ANLY580\\datasets\" will be used to save temporary dictionary and corpus.\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os.path\n",
    "\n",
    "TEMP_FOLDER = 'D:\\OneDrive\\ANLY580\\datasets'\n",
    "print('Folder \"{}\" will be used to save temporary dictionary and corpus.'.format(TEMP_FOLDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isunl\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2017-10-25 12:59:30,486 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2017-10-25 12:59:30,524 : INFO : loading Dictionary object from D:\\OneDrive\\ANLY580\\datasets\\deerwester.dict\n",
      "2017-10-25 12:59:30,530 : INFO : loaded D:\\OneDrive\\ANLY580\\datasets\\deerwester.dict\n",
      "2017-10-25 12:59:30,536 : INFO : loaded corpus index from D:\\OneDrive\\ANLY580\\datasets\\deerwester.mm.index\n",
      "2017-10-25 12:59:30,537 : INFO : initializing corpus reader from D:\\OneDrive\\ANLY580\\datasets\\deerwester.mm\n",
      "2017-10-25 12:59:30,542 : INFO : accepted corpus with 9 documents, 12 features, 28 non-zero entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used files generated from first tutorial\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "if os.path.isfile(os.path.join(TEMP_FOLDER, 'deerwester.dict')):\n",
    "    dictionary = corpora.Dictionary.load(os.path.join(TEMP_FOLDER, 'deerwester.dict'))\n",
    "    corpus = corpora.MmCorpus(os.path.join(TEMP_FOLDER, 'deerwester.mm'))\n",
    "    print(\"Used files generated from first tutorial\")\n",
    "else:\n",
    "    print(\"Please run first tutorial to generate data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human\n",
      "interface\n",
      "computer\n"
     ]
    }
   ],
   "source": [
    "print(dictionary[0])\n",
    "print(dictionary[1])\n",
    "print(dictionary[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating a transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-25 12:59:30,557 : INFO : collecting document frequencies\n",
      "2017-10-25 12:59:30,558 : INFO : PROGRESS: processing document #0\n",
      "2017-10-25 12:59:30,560 : INFO : calculating IDF weights for 9 documents and 11 features (28 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.7071067811865476), (1, 0.7071067811865476)]\n"
     ]
    }
   ],
   "source": [
    "doc_bow = [(0, 1), (1, 1)]\n",
    "print(tfidf[doc_bow]) # step 2 -- use the model to transform vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(2, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.3244870206138555), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.44424552527467476)]\n",
      "[(1, 0.5710059809418182), (4, 0.4170757362022777), (5, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(0, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(4, 0.45889394536615247), (6, 0.6282580468670046), (7, 0.6282580468670046)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(3, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "corpus_tfidf = tfidf[corpus]\n",
    "for doc in corpus_tfidf:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-25 12:59:30,585 : INFO : using serial LSI version on this node\n",
      "2017-10-25 12:59:30,586 : INFO : updating model with new documents\n",
      "2017-10-25 12:59:30,588 : INFO : preparing a new chunk of documents\n",
      "2017-10-25 12:59:30,589 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-10-25 12:59:30,590 : INFO : 1st phase: constructing (12, 102) action matrix\n",
      "2017-10-25 12:59:30,592 : INFO : orthonormalizing (12, 102) action matrix\n",
      "2017-10-25 12:59:30,618 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
      "2017-10-25 12:59:30,631 : INFO : computing the final decomposition\n",
      "2017-10-25 12:59:30,632 : INFO : keeping 2 factors (discarding 47.565% of energy spectrum)\n",
      "2017-10-25 12:59:30,635 : INFO : processed documents up to #9\n",
      "2017-10-25 12:59:30,636 : INFO : topic #0(1.594): -0.703*\"trees\" + -0.538*\"graph\" + -0.402*\"minors\" + -0.187*\"survey\" + -0.061*\"system\" + -0.060*\"time\" + -0.060*\"response\" + -0.058*\"user\" + -0.049*\"computer\" + -0.035*\"interface\"\n",
      "2017-10-25 12:59:30,638 : INFO : topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"time\" + -0.320*\"response\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2) # initialize an LSI transformation\n",
    "corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-25 12:59:30,643 : INFO : topic #0(1.594): -0.703*\"trees\" + -0.538*\"graph\" + -0.402*\"minors\" + -0.187*\"survey\" + -0.061*\"system\" + -0.060*\"time\" + -0.060*\"response\" + -0.058*\"user\" + -0.049*\"computer\" + -0.035*\"interface\"\n",
      "2017-10-25 12:59:30,645 : INFO : topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"time\" + -0.320*\"response\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '-0.703*\"trees\" + -0.538*\"graph\" + -0.402*\"minors\" + -0.187*\"survey\" + -0.061*\"system\" + -0.060*\"time\" + -0.060*\"response\" + -0.058*\"user\" + -0.049*\"computer\" + -0.035*\"interface\"'),\n",
       " (1,\n",
       "  '-0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"time\" + -0.320*\"response\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, -0.066007833960903567), (1, -0.52007033063618602)]\n",
      "[(0, -0.19667592859142471), (1, -0.76095631677000464)]\n",
      "[(0, -0.089926399724463701), (1, -0.72418606267525165)]\n",
      "[(0, -0.075858476521781376), (1, -0.63205515860034356)]\n",
      "[(0, -0.10150299184980109), (1, -0.57373084830029519)]\n",
      "[(0, -0.70321089393783154), (1, 0.16115180214025795)]\n",
      "[(0, -0.87747876731198393), (1, 0.16758906864659415)]\n",
      "[(0, -0.90986246868185883), (1, 0.14086553628719023)]\n",
      "[(0, -0.61658253505692873), (1, -0.0539290756638936)]\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus_lsi: # both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-25 13:00:39,355 : INFO : collecting document frequencies\n",
      "2017-10-25 13:00:39,357 : INFO : PROGRESS: processing document #0\n",
      "2017-10-25 13:00:39,358 : INFO : calculating IDF weights for 9 documents and 11 features (28 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "model = models.TfidfModel(corpus, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ecf61c0b7309>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLsiModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_corpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "model = models.LsiModel(tfidf_corpus, id2word=dictionary, num_topics=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
